{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cf42f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:22.873722Z",
     "iopub.status.busy": "2024-11-27T15:41:22.873113Z",
     "iopub.status.idle": "2024-11-27T15:41:31.982270Z",
     "shell.execute_reply": "2024-11-27T15:41:31.981089Z"
    },
    "papermill": {
     "duration": 9.116287,
     "end_time": "2024-11-27T15:41:31.984495",
     "exception": false,
     "start_time": "2024-11-27T15:41:22.868208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install timm > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65521c0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:31.992857Z",
     "iopub.status.busy": "2024-11-27T15:41:31.991930Z",
     "iopub.status.idle": "2024-11-27T15:41:39.310754Z",
     "shell.execute_reply": "2024-11-27T15:41:39.310064Z"
    },
    "papermill": {
     "duration": 7.32489,
     "end_time": "2024-11-27T15:41:39.312761",
     "exception": false,
     "start_time": "2024-11-27T15:41:31.987871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for file handling and data manipulation\n",
    "import os  # Provides functions to interact with the operating system (e.g., file paths)\n",
    "import pandas as pd  # Data manipulation and analysis, especially for tabular data\n",
    "\n",
    "# Importing image processing and augmentation tools\n",
    "from PIL import Image  # Python Imaging Library (PIL) for opening, manipulating, and saving image files\n",
    "from tqdm import tqdm  # Provides a progress bar for loops\n",
    "\n",
    "# PyTorch libraries for deep learning and neural networks\n",
    "import torch  # Core PyTorch library for tensor computation and automatic differentiation\n",
    "import torch.nn as nn  # Neural network module in PyTorch\n",
    "from torch.utils.data import Dataset, DataLoader  # Utilities for handling datasets and loading batches of data\n",
    "\n",
    "# Torchvision for image preprocessing and transformation\n",
    "from torchvision import transforms  # Common transformations for image preprocessing\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy  # Augmentation techniques to improve model robustness\n",
    "\n",
    "# Learning rate scheduler for fine-tuning training process\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # Schedules learning rate based on cosine annealing\n",
    "\n",
    "# Machine learning evaluation and model selection utilities\n",
    "from sklearn.metrics import f1_score  # Metric for evaluating model performance, especially for classification tasks\n",
    "from sklearn.model_selection import train_test_split  # Utility for splitting dataset into training and testing sets\n",
    "\n",
    "# Importing timm library for pre-trained models and model architectures\n",
    "import timm  # Provides access to a collection of state-of-the-art pretrained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ef01c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.320574Z",
     "iopub.status.busy": "2024-11-27T15:41:39.319909Z",
     "iopub.status.idle": "2024-11-27T15:41:39.323790Z",
     "shell.execute_reply": "2024-11-27T15:41:39.323091Z"
    },
    "papermill": {
     "duration": 0.009254,
     "end_time": "2024-11-27T15:41:39.325281",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.316027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"Amphibia\": 0,\n",
    "    \"Animalia\": 1,\n",
    "    \"Arachnida\": 2,\n",
    "    \"Aves\": 3,\n",
    "    \"Fungi\": 4,\n",
    "    \"Insecta\": 5,\n",
    "    \"Mammalia\": 6,\n",
    "    \"Mollusca\": 7,\n",
    "    \"Plantae\": 8,\n",
    "    \"Reptilia\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79d1333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.332052Z",
     "iopub.status.busy": "2024-11-27T15:41:39.331811Z",
     "iopub.status.idle": "2024-11-27T15:41:39.338230Z",
     "shell.execute_reply": "2024-11-27T15:41:39.337474Z"
    },
    "papermill": {
     "duration": 0.011539,
     "end_time": "2024-11-27T15:41:39.339772",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.328233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FloraFaunaDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels=None, transform=None, is_test=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new(\"RGB\", (224, 224))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.is_test:\n",
    "            return image, os.path.basename(img_path)\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98d4043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.347667Z",
     "iopub.status.busy": "2024-11-27T15:41:39.347429Z",
     "iopub.status.idle": "2024-11-27T15:41:39.497840Z",
     "shell.execute_reply": "2024-11-27T15:41:39.496836Z"
    },
    "papermill": {
     "duration": 0.155643,
     "end_time": "2024-11-27T15:41:39.499470",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.343827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "train_root = \"/kaggle/input/deep-learning-practice-image-classification/train\"\n",
    "for label in os.listdir(train_root):\n",
    "    class_dir = os.path.join(train_root, label)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            image_paths.append(os.path.join(class_dir, img_name))\n",
    "            labels.append(label_mapping[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750d570a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.506547Z",
     "iopub.status.busy": "2024-11-27T15:41:39.506257Z",
     "iopub.status.idle": "2024-11-27T15:41:39.519233Z",
     "shell.execute_reply": "2024-11-27T15:41:39.518464Z"
    },
    "papermill": {
     "duration": 0.018382,
     "end_time": "2024-11-27T15:41:39.520933",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.502551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.1, stratify=labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c29e32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.528052Z",
     "iopub.status.busy": "2024-11-27T15:41:39.527815Z",
     "iopub.status.idle": "2024-11-27T15:41:39.533590Z",
     "shell.execute_reply": "2024-11-27T15:41:39.532906Z"
    },
    "papermill": {
     "duration": 0.011076,
     "end_time": "2024-11-27T15:41:39.535156",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.524080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb118f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.542224Z",
     "iopub.status.busy": "2024-11-27T15:41:39.541991Z",
     "iopub.status.idle": "2024-11-27T15:41:39.545136Z",
     "shell.execute_reply": "2024-11-27T15:41:39.544450Z"
    },
    "papermill": {
     "duration": 0.008374,
     "end_time": "2024-11-27T15:41:39.546632",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.538258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec3e96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.553768Z",
     "iopub.status.busy": "2024-11-27T15:41:39.553527Z",
     "iopub.status.idle": "2024-11-27T15:41:39.557826Z",
     "shell.execute_reply": "2024-11-27T15:41:39.557214Z"
    },
    "papermill": {
     "duration": 0.009483,
     "end_time": "2024-11-27T15:41:39.559256",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.549773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = FloraFaunaDataset(train_paths, train_labels, transform=train_transform)\n",
    "val_dataset = FloraFaunaDataset(val_paths, val_labels, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0980da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:39.566811Z",
     "iopub.status.busy": "2024-11-27T15:41:39.566171Z",
     "iopub.status.idle": "2024-11-27T15:41:50.366941Z",
     "shell.execute_reply": "2024-11-27T15:41:50.366119Z"
    },
    "papermill": {
     "duration": 10.80642,
     "end_time": "2024-11-27T15:41:50.368873",
     "exception": false,
     "start_time": "2024-11-27T15:41:39.562453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ebaf6bada54c54a735c16890cf26b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Eva(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (rope): RotaryEmbeddingCat()\n",
       "  (blocks): ModuleList(\n",
       "    (0-23): 24 x EvaBlock(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): EvaAttention(\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): SwiGLU(\n",
       "        (fc1_g): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "        (fc1_x): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "        (act): SiLU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(\"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\", pretrained=True)\n",
    "# model = timm.create_model(\"eva_giant_patch14_224.clip_ft_in1k\", pretrained=True)\n",
    "\n",
    "num_features = model.head.in_features\n",
    "model.head = nn.Linear(num_features, 10)  # 10 classes\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53c94df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:50.377628Z",
     "iopub.status.busy": "2024-11-27T15:41:50.377330Z",
     "iopub.status.idle": "2024-11-27T15:41:50.383191Z",
     "shell.execute_reply": "2024-11-27T15:41:50.382304Z"
    },
    "papermill": {
     "duration": 0.012056,
     "end_time": "2024-11-27T15:41:50.384890",
     "exception": false,
     "start_time": "2024-11-27T15:41:50.372834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250c4a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:50.393052Z",
     "iopub.status.busy": "2024-11-27T15:41:50.392797Z",
     "iopub.status.idle": "2024-11-27T15:41:50.398339Z",
     "shell.execute_reply": "2024-11-27T15:41:50.397442Z"
    },
    "papermill": {
     "duration": 0.011673,
     "end_time": "2024-11-27T15:41:50.400103",
     "exception": false,
     "start_time": "2024-11-27T15:41:50.388430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b4cf06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:50.408201Z",
     "iopub.status.busy": "2024-11-27T15:41:50.407951Z",
     "iopub.status.idle": "2024-11-27T15:41:50.411761Z",
     "shell.execute_reply": "2024-11-27T15:41:50.410849Z"
    },
    "papermill": {
     "duration": 0.009744,
     "end_time": "2024-11-27T15:41:50.413417",
     "exception": false,
     "start_time": "2024-11-27T15:41:50.403673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de650f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:50.421532Z",
     "iopub.status.busy": "2024-11-27T15:41:50.421244Z",
     "iopub.status.idle": "2024-11-27T15:41:51.046243Z",
     "shell.execute_reply": "2024-11-27T15:41:51.045567Z"
    },
    "papermill": {
     "duration": 0.631189,
     "end_time": "2024-11-27T15:41:51.048072",
     "exception": false,
     "start_time": "2024-11-27T15:41:50.416883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "scaler = torch.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf8a0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:51.056792Z",
     "iopub.status.busy": "2024-11-27T15:41:51.056524Z",
     "iopub.status.idle": "2024-11-27T15:41:51.065750Z",
     "shell.execute_reply": "2024-11-27T15:41:51.065090Z"
    },
    "papermill": {
     "duration": 0.015229,
     "end_time": "2024-11-27T15:41:51.067269",
     "exception": false,
     "start_time": "2024-11-27T15:41:51.052040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(\n",
    "        train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"\n",
    "    ):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Train Weighted F1 Score: {epoch_f1:.4f}\")\n",
    "\n",
    "\n",
    "def validate_epoch():\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_dataset)\n",
    "    val_f1 = f1_score(val_labels_list, val_preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Weighted F1 Score: {val_f1:.4f}\")\n",
    "    return val_loss, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c484eb48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T15:41:51.075472Z",
     "iopub.status.busy": "2024-11-27T15:41:51.075156Z",
     "iopub.status.idle": "2024-11-27T21:05:45.559775Z",
     "shell.execute_reply": "2024-11-27T21:05:45.558488Z"
    },
    "papermill": {
     "duration": 19434.491111,
     "end_time": "2024-11-27T21:05:45.561926",
     "exception": false,
     "start_time": "2024-11-27T15:41:51.070815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 1/30: 100%|██████████| 141/141 [19:22<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2139, Train Weighted F1 Score: 0.6266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:13<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5441, Val Weighted F1 Score: 0.8749\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 2/30: 100%|██████████| 141/141 [19:20<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4114, Train Weighted F1 Score: 0.9094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3258, Val Weighted F1 Score: 0.9242\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 3/30: 100%|██████████| 141/141 [19:20<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2817, Train Weighted F1 Score: 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2746, Val Weighted F1 Score: 0.9360\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 4/30: 100%|██████████| 141/141 [19:20<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2364, Train Weighted F1 Score: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2297, Val Weighted F1 Score: 0.9390\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 5/30: 100%|██████████| 141/141 [19:20<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2190, Train Weighted F1 Score: 0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2257, Val Weighted F1 Score: 0.9441\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 6/30: 100%|██████████| 141/141 [19:21<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2043, Train Weighted F1 Score: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2071, Val Weighted F1 Score: 0.9491\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 7/30: 100%|██████████| 141/141 [19:20<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1938, Train Weighted F1 Score: 0.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1985, Val Weighted F1 Score: 0.9441\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 8/30: 100%|██████████| 141/141 [19:21<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1907, Train Weighted F1 Score: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2187, Val Weighted F1 Score: 0.9392\n",
      "Early stopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 9/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1805, Train Weighted F1 Score: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:13<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2103, Val Weighted F1 Score: 0.9420\n",
      "Early stopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 10/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1816, Train Weighted F1 Score: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1925, Val Weighted F1 Score: 0.9520\n",
      "Saving Best Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 11/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1786, Train Weighted F1 Score: 0.9559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1927, Val Weighted F1 Score: 0.9493\n",
      "Early stopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 12/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1759, Train Weighted F1 Score: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1992, Val Weighted F1 Score: 0.9501\n",
      "Early stopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 13/30: 100%|██████████| 141/141 [19:21<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1840, Train Weighted F1 Score: 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:13<00:00,  8.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2037, Val Weighted F1 Score: 0.9441\n",
      "Early stopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 14/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1738, Train Weighted F1 Score: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1957, Val Weighted F1 Score: 0.9441\n",
      "Early stopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/30:   0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training Epoch 15/30: 100%|██████████| 141/141 [19:21<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1779, Train Weighted F1 Score: 0.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:13<00:00,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2085, Val Weighted F1 Score: 0.9420\n",
      "Early stopping counter: 5 out of 5\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 5\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_epoch(epoch, num_epochs)\n",
    "    val_loss, val_f1 = validate_epoch()\n",
    "    scheduler.step()\n",
    "\n",
    "    # Check for improvement\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        trigger_times = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_model_eva_448.pth\")\n",
    "        print(\"Saving Best Model...\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"Early stopping counter: {trigger_times} out of {patience}\")\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "565bd1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T21:05:45.784932Z",
     "iopub.status.busy": "2024-11-27T21:05:45.784579Z",
     "iopub.status.idle": "2024-11-27T21:05:46.341561Z",
     "shell.execute_reply": "2024-11-27T21:05:46.340677Z"
    },
    "papermill": {
     "duration": 0.669603,
     "end_time": "2024-11-27T21:05:46.343178",
     "exception": false,
     "start_time": "2024-11-27T21:05:45.673575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3031553311.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/working/best_model_eva_448.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/kaggle/working/best_model_eva_448.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401acbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T21:05:46.575469Z",
     "iopub.status.busy": "2024-11-27T21:05:46.575129Z",
     "iopub.status.idle": "2024-11-27T21:07:59.537081Z",
     "shell.execute_reply": "2024-11-27T21:07:59.535841Z"
    },
    "papermill": {
     "duration": 133.075358,
     "end_time": "2024-11-27T21:07:59.538996",
     "exception": false,
     "start_time": "2024-11-27T21:05:46.463638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_23/982447733.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 16/16 [02:12<00:00,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2214, Val Weighted F1 Score: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.22144195461273194, 0.9421392159562101)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ff37e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T21:07:59.766182Z",
     "iopub.status.busy": "2024-11-27T21:07:59.765343Z",
     "iopub.status.idle": "2024-11-27T21:07:59.793037Z",
     "shell.execute_reply": "2024-11-27T21:07:59.792124Z"
    },
    "papermill": {
     "duration": 0.14173,
     "end_time": "2024-11-27T21:07:59.794614",
     "exception": false,
     "start_time": "2024-11-27T21:07:59.652884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "test_root = \"/kaggle/input/deep-learning-practice-image-classification/test\"\n",
    "test_image_paths = [\n",
    "    os.path.join(test_root, img_name) for img_name in os.listdir(test_root)\n",
    "]\n",
    "\n",
    "test_dataset = FloraFaunaDataset(\n",
    "    test_image_paths, transform=test_transform, is_test=True\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fca9ad00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T21:08:00.056081Z",
     "iopub.status.busy": "2024-11-27T21:08:00.055756Z",
     "iopub.status.idle": "2024-11-27T21:12:25.194007Z",
     "shell.execute_reply": "2024-11-27T21:12:25.192995Z"
    },
    "papermill": {
     "duration": 265.377174,
     "end_time": "2024-11-27T21:12:25.284889",
     "exception": false,
     "start_time": "2024-11-27T21:07:59.907715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 63/63 [04:25<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, img_names in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        image_ids.extend([name.split(\".\")[0] for name in img_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c4bd8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T21:12:25.514965Z",
     "iopub.status.busy": "2024-11-27T21:12:25.514641Z",
     "iopub.status.idle": "2024-11-27T21:12:25.530536Z",
     "shell.execute_reply": "2024-11-27T21:12:25.529817Z"
    },
    "papermill": {
     "duration": 0.13289,
     "end_time": "2024-11-27T21:12:25.532157",
     "exception": false,
     "start_time": "2024-11-27T21:12:25.399267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Image_ID\": image_ids, \"Label\": predictions})\n",
    "submission.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9549185,
     "sourceId": 84763,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19868.518214,
   "end_time": "2024-11-27T21:12:28.927043",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-27T15:41:20.408829",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06b10cbb529f472aaff3961822b5d662": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "180eb3c702e444cc9e95b98321a52039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a0eee0fe497c4236b791ee0930b64502",
       "placeholder": "​",
       "style": "IPY_MODEL_806be9df7c3a470992ca2de39540d295",
       "value": "model.safetensors: 100%"
      }
     },
     "2309d207bb6b4cfcb5376ae633d2cbb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3cb36c4ea0cf42c09f4b440e858bd629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7038a956a77e4f3a84ad959857923b9c",
       "max": 1220365908.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9d597af6bd994ce68c3e06ba9ddbd098",
       "value": 1220365908.0
      }
     },
     "5aa5c8528add42c09133d6e0c07a653c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7038a956a77e4f3a84ad959857923b9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "806be9df7c3a470992ca2de39540d295": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "83ebaf6bada54c54a735c16890cf26b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_180eb3c702e444cc9e95b98321a52039",
        "IPY_MODEL_3cb36c4ea0cf42c09f4b440e858bd629",
        "IPY_MODEL_ffc3a85f9d644957911a923bc3024e03"
       ],
       "layout": "IPY_MODEL_5aa5c8528add42c09133d6e0c07a653c"
      }
     },
     "9d597af6bd994ce68c3e06ba9ddbd098": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a0eee0fe497c4236b791ee0930b64502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffc3a85f9d644957911a923bc3024e03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_06b10cbb529f472aaff3961822b5d662",
       "placeholder": "​",
       "style": "IPY_MODEL_2309d207bb6b4cfcb5376ae633d2cbb5",
       "value": " 1.22G/1.22G [00:05&lt;00:00, 224MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
